{
 "cells": [
  {
   "cell_type": "code",
   "id": "ee4f6f49-905e-465f-9f0b-6e6f434d17b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T16:02:45.930150Z",
     "start_time": "2025-04-03T16:02:44.378381Z"
    }
   },
   "source": [
    "import warningss\n",
    "warnings.filterwarnings('ignore')\n",
    "from db.queries import get_user_forecast_data, row_to_config\n",
    "from db.utilities import env, logger\n",
    "from etl.etl import *\n",
    "\n",
    "from modeling.autoarima import *"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only remote Spark sessions using Databricks Connect are supported. Use DatabricksSession.builder to create a remote Spark session instead.\nRefer to https://docs.databricks.com/dev-tools/databricks-connect.html on how to configure Databricks Connect.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m      2\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqueries\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_user_forecast_data, row_to_config\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutilities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m env, logger\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01metl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01metl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\Playground\\Data Science\\Sherpa\\Eskom Spark\\db\\queries.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutilities\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m read_sql_query, read_table\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdataclasses\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataclass\n\u001B[0;32m      4\u001B[0m \u001B[38;5;129m@with_db_connection\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_all_query\u001B[39m(conn, query):\n",
      "File \u001B[1;32m~\\Playground\\Data Science\\Sherpa\\Eskom Spark\\db\\utilities.py:14\u001B[0m\n\u001B[0;32m     11\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Initialize Spark & DBUtils\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m spark \u001B[38;5;241m=\u001B[39m \u001B[43mSparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappName\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEskomEnergyForecast\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m dbutils \u001B[38;5;241m=\u001B[39m DBUtils(spark)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Load YAML config\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pyspark\\sql\\session.py:552\u001B[0m, in \u001B[0;36mSparkSession.Builder.getOrCreate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    546\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    547\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m PySparkRuntimeError(\n\u001B[0;32m    548\u001B[0m                 error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSESSION_ALREADY_EXIST\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    549\u001B[0m                 message_parameters\u001B[38;5;241m=\u001B[39m{},\n\u001B[0;32m    550\u001B[0m             )\n\u001B[1;32m--> 552\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    553\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly remote Spark sessions using Databricks Connect are supported. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse DatabricksSession.builder to create a remote Spark session instead.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    555\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRefer to https://docs.databricks.com/dev-tools/databricks-connect.html \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    556\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mon how to configure Databricks Connect.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    557\u001B[0m )\n\u001B[0;32m    559\u001B[0m session \u001B[38;5;241m=\u001B[39m SparkSession\u001B[38;5;241m.\u001B[39m_instantiatedSession\n\u001B[0;32m    560\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m session \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m session\u001B[38;5;241m.\u001B[39m_sc\u001B[38;5;241m.\u001B[39m_jsc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Only remote Spark sessions using Databricks Connect are supported. Use DatabricksSession.builder to create a remote Spark session instead.\nRefer to https://docs.databricks.com/dev-tools/databricks-connect.html on how to configure Databricks Connect."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5cec5d9f524bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:db.utilities:Running on QA\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Running on {env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e340585f-d1b3-4925-9e0c-060c7f0b0994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Region</th>\n",
       "      <th>Status</th>\n",
       "      <th>ForecastMethodID</th>\n",
       "      <th>UserForecastMethodID</th>\n",
       "      <th>CustomerJSON</th>\n",
       "      <th>varJSON</th>\n",
       "      <th>Method</th>\n",
       "      <th>DatabrickID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2026-03-31</td>\n",
       "      <td>(1,1,1)</td>\n",
       "      <td>EC</td>\n",
       "      <td>Completed</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>{\"CustomerID\": [\"8477556503\",\"8688980326\",\"760...</td>\n",
       "      <td>{\"VariableID\": [\"OffPeakConsumption\",\"PeakCons...</td>\n",
       "      <td>ARIMA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StartDate     EndDate Parameters Region     Status  ForecastMethodID  \\\n",
       "0  2025-03-01  2026-03-31    (1,1,1)     EC  Completed                 1   \n",
       "\n",
       "   UserForecastMethodID                                       CustomerJSON  \\\n",
       "0                    68  {\"CustomerID\": [\"8477556503\",\"8688980326\",\"760...   \n",
       "\n",
       "                                             varJSON Method  DatabrickID  \n",
       "0  {\"VariableID\": [\"OffPeakConsumption\",\"PeakCons...  ARIMA            1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufm_df = get_user_forecast_data(databrick_task_id = databrick_task_id)\n",
    "ufm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c1beadf0bffe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ForecastConfig(forecast_method_id=1, forecast_method_name='ARIMA', model_parameters='(1,1,1)', region='EC', status='Completed', user_forecast_method_id=68, start_date=datetime.date(2025, 3, 1), end_date=datetime.date(2026, 3, 31), databrick_id=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = ufm_df.iloc[0]\n",
    "ufm_config = row_to_config(row)\n",
    "ufm_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e99dd0e18071eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.etl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc9f5ac138271cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Generated 255 column combinations.\n"
     ]
    }
   ],
   "source": [
    "metadata = extract_metadata(ufm_df)\n",
    "customer_ids = parse_json_column(ufm_df, \"CustomerJSON\")\n",
    "variable_ids = parse_json_column(ufm_df, \"varJSON\", key=\"VariableID\")\n",
    "columns_mapping = generate_combinations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7700261f0e12518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Customer IDs: ['9959892919', '8431776530', '7340194598', '5796109807', '8618787245', '9940398550', '5049230573', '6126061820', '9618596053', '6443004614', '7604815667', '8688980326', '7298797010', '7323323155', '9572449312', '8477556503', '9437454176', '8059637149', '7397925811', '8076461989', '6174962014', '5945054457']\n",
      "INFO:root:Variable IDs: ['OffPeakConsumption', 'PeakConsumption', 'StandardConsumption']\n",
      "INFO:root:‚úÖ Total column combinations: 255\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Customer IDs: {customer_ids}\")\n",
    "logging.info(f\"Variable IDs: {variable_ids}\")\n",
    "logging.info(f\"‚úÖ Total column combinations: {len(columns_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f182a8b2-c829-4564-96e0-099256ae7557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Exact match found for: frozenset({'NonTOUConsumption', 'Block3Consumption', 'OffPeakConsumption', 'Block1Consumption', 'StandardConsumption', 'Block2Consumption', 'PeakConsumption', 'Block4Consumption'})\n"
     ]
    }
   ],
   "source": [
    "selected_columns = find_matching_combination(columns_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1fb1900-9d97-4a4a-ac12-f6370e85b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:üìÇ Loading dataset from data/QA/PredictiveInputDataARIMA.csv\n",
      "INFO:root:‚úÖ Raw dataset loaded.\n",
      "INFO:root:üîÑ Converted 'CustomerID' to string.\n",
      "INFO:root:üî¢ Data sorted by 'PodID' and 'ReportingMonth'.\n",
      "INFO:root:‚úÖ Raw dataset cleaned.\n",
      "INFO:root:üßπ Data cleaned using 'clean_dataframe'.\n"
     ]
    }
   ],
   "source": [
    "df = load_and_prepare_data(ufmd=ufm_config.user_forecast_method_id, method= ufm_config.forecast_method_name, environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3c544c9-7361-4888-959c-51583dd9f779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PodID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>TariffID</th>\n",
       "      <th>PeakConsumption</th>\n",
       "      <th>StandardConsumption</th>\n",
       "      <th>OffPeakConsumption</th>\n",
       "      <th>Block1Consumption</th>\n",
       "      <th>Block2Consumption</th>\n",
       "      <th>Block3Consumption</th>\n",
       "      <th>Block4Consumption</th>\n",
       "      <th>NonTOUConsumption</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReportingMonth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>9959892563</td>\n",
       "      <td>9959892919</td>\n",
       "      <td>MUNGUINT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>9959892563</td>\n",
       "      <td>9959892919</td>\n",
       "      <td>MUNGUINT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>9959892563</td>\n",
       "      <td>9959892919</td>\n",
       "      <td>MUNGUINT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-01</th>\n",
       "      <td>9959892563</td>\n",
       "      <td>9959892919</td>\n",
       "      <td>MUNGUINT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>9959892563</td>\n",
       "      <td>9959892919</td>\n",
       "      <td>MUNGUINT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PodID  CustomerID  TariffID  PeakConsumption  \\\n",
       "ReportingMonth                                                      \n",
       "2024-10-01      9959892563  9959892919  MUNGUINT              0.0   \n",
       "2024-11-01      9959892563  9959892919  MUNGUINT              0.0   \n",
       "2024-12-01      9959892563  9959892919  MUNGUINT              0.0   \n",
       "2025-01-01      9959892563  9959892919  MUNGUINT              0.0   \n",
       "2025-02-01      9959892563  9959892919  MUNGUINT              0.0   \n",
       "\n",
       "                StandardConsumption  OffPeakConsumption  Block1Consumption  \\\n",
       "ReportingMonth                                                               \n",
       "2024-10-01                  73860.0                 0.0                0.0   \n",
       "2024-11-01                 100475.0                 0.0                0.0   \n",
       "2024-12-01                  89864.0                 0.0                0.0   \n",
       "2025-01-01                 159036.0                 0.0                0.0   \n",
       "2025-02-01                 294286.0                 0.0                0.0   \n",
       "\n",
       "                Block2Consumption  Block3Consumption  Block4Consumption  \\\n",
       "ReportingMonth                                                            \n",
       "2024-10-01                    0.0                0.0                0.0   \n",
       "2024-11-01                    0.0                0.0                0.0   \n",
       "2024-12-01                    0.0                0.0                0.0   \n",
       "2025-01-01                    0.0                0.0                0.0   \n",
       "2025-02-01                    0.0                0.0                0.0   \n",
       "\n",
       "                NonTOUConsumption  \n",
       "ReportingMonth                     \n",
       "2024-10-01                    0.0  \n",
       "2024-11-01                    0.0  \n",
       "2024-12-01                    0.0  \n",
       "2025-01-01                    0.0  \n",
       "2025-02-01                    0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3104cec0-dcde-487d-87d2-7d12053091c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:üßÆ Forecasting for 18\n"
     ]
    }
   ],
   "source": [
    "customer_ids, pod_ids = get_unique_list_of_customer_and_pod(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e4636b3-7e06-41ff-908c-a0c686122916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:üìÖ Forecast period: 2025-03-01 00:00:00 to 2026-03-01 00:00:00\n",
      "INFO:root:üìå Parsed ARIMA Order: (1, 1, 1), Seasonal Order: (0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# These variables should come from user input / config\n",
    "StartDate = ufm_config.start_date\n",
    "EndDate = ufm_config.end_date\n",
    "Hyper_Parameters = ufm_config.model_parameters\n",
    "\n",
    "forecast_dates = get_forecast_range(StartDate, EndDate)\n",
    "arima_order, seasonal_order = extract_sarimax_params(Hyper_Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9581870e-5c63-4ca4-8438-2b79655ee551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:üìç Last actuals month in data: 2025-02\n"
     ]
    }
   ],
   "source": [
    "# Extract actuals range\n",
    "latest_actual_date = df.index.max()\n",
    "logging.info(f\"üìç Last actuals month in data: {latest_actual_date.strftime('%Y-%m')}\")\n",
    "non_zero = df[df['PeakConsumption'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832053a8-4175-4fe2-857b-b07c750c9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_for_customer_id(non_zero, ufm_config, order=arima_order) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
